# Error Analysis and Insights

During the robust offline evaluation phase, we identified several edge cases and model behaviors that inform our deployment limitations and required safeguards.

## 1. Metric: Precision @ K
*   While our Model achieved a HitRate of over 0.45 across tests, its Precision@8 remained intentionally low ($~0.08$). 
*   **Insight:** This is fundamentally a mathematical constraint of Implicit Feedback recommendation algorithms predicting a single definitive cart-pairing vs an array. A generated list of 5 items might contain genuinely fantastic recommendations (like "Fries" and "Coke"), but if the user *specifically* only clicked on "Mustard" in that true order, the model is mathematically penalized on all 4 other valid suggestions.
*   **Conclusion:** In production, A/B Testing Click-Through Rates will be a much stronger true indicator of success than the hyper-strict Precision metric offline.

## 2. Model Constraint: Cold-Start Item Similarity
*   **Error Class:** Sometimes, `sentence-transformers` assigns seemingly disparate dishes a high Cosine Similarity because they share English adjectives (e.g., "Sweet Lassi" vs "Sweet Chili Sauce"). 
*   **Solution Implemented:** This error was observed early on. We solved this by implementing the specific Knowledge Graph architecture. Vectors are matched *only within* specific culturally-guarded Candidate generation arrays instead of against the raw universe of 350+ dishes.

## 3. Margin Errors: "Water" Fallbacks
*   **Observation:** The LightGBM ranker has a heavy tendency to push "Water" and "Coke" to position #1 for all 'Budget' segmented users.
*   **Insight:** While mathematically "correct" historically (people buy water constantly), from a business context this limits actual margin growth by missing out on recommending actual profitable sides.
*   **Recommendation:** Apply a post-processing business-logic rule in `inference.py` to actively penalize "Water" by `-20%` score forcing the model to display at least 2 food-based sides to every Budget user.
## 4. Handling Incomplete Meal Patterns / Data Sparsity (Cold Start)
*   **Challenge:** New Zomato users or users who only ever order Breakfast will have sparse or missing historical data (`user_historical_veg_ratio`, `order_frequency`), making traditional collaborative filtering fail.
*   **Solution Strategy:** Our Two-Stage architecture organically solves Data Sparsity. 
    *   **Fallback Heuristics:** If user history is missing, `inference.py` defaults to generic segments ("Budget" user, 50% Veg ratio). 
    *   **Context over History:** The Stage 1 Vector Semantic Search ignores user history entirely, focusing purely on solving the *immediate contextual intent* of the cart itself. If a brand new user adds "Pizza" to their cart, our vector embeddings guarantee "Coke" and "Garlic Bread" are recommended via context, successfully completely bypassing the Cold Start data sparsity problem.
